{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comparar Algoritmos**\n",
    "\n",
    "# _Objetivo_\n",
    "\n",
    "- Realizar entrenamiento para los tipos de modelos.\n",
    "- Realizar Stratified K-Fold Cross-Validation (Validación cruzada estratificada de K particiones).\n",
    "- Realizar K-Fold Cross-Validation (Validación cruzada estratificada de K particiones).\n",
    "- Realizar entrenamiento y prediccion en cada kfold.\n",
    "- Realizar prediccion sobre el test del entrenamiento, asi obtener el mejor modelo.\n",
    "- Revisar los resultados obtenidos.\n",
    "- Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Liberias_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../resources/allColProSol.xlsx\n",
      "../resources/dataset_a_2021.csv\n",
      "../resources/dataset_a_2021c2.csv\n",
      "../resources/dataset_a_2021v1.xlsx\n",
      "../resources/dataset_unab_ORIGINAL SIN P1.csv\n",
      "../resources/dataset_unab_P1.csv\n",
      "../resources/exitoFallidoEnviosProgramaSol.xlsx\n",
      "../resources/exitoFallidoProgramaSol.xlsx\n",
      "../resources/exitosoFallidosEnviosAllColProSol.xlsx\n",
      "../resources/exitosoFallidosEnviosAllColSol.xlsx\n",
      "../resources/exitososFallidosEnviosSol.xlsx\n",
      "../resources/Hito12sinColCeroExitosoFallidosSol.xlsx\n",
      "../resources/sinColCeroExitosoFallidosEnviosSol.xlsx\n",
      "../resources/sinColCeroExitosoFallidosSol.xlsx\n",
      "../resources/v2_hitosExitoFalloColESol1.csv\n",
      "../resources/v2_hitosExitoFalloColESol1Prograna.csv\n",
      "../resources/v2_hitosExitoFalloSol1Programa.csv\n",
      "../resources/causalidad\\causalidad_e29.dot\n",
      "../resources/causalidad\\graph_causal_model_e29.png\n",
      "../resources/causalidad\\graph_causal_model_e3.png\n",
      "../resources/causalidad\\graph_causal_model_e35.png\n",
      "../resources/causalidad\\graph_causal_model_e3_full.png\n",
      "../resources/causalidad\\graph_causal_model_e42.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Importa la biblioteca numpy para operaciones numéricas eficientes\n",
    "import pandas as pd  # Importa la biblioteca pandas para el análisis y manipulación de datos\n",
    "import matplotlib.pyplot as plt  # Importa la biblioteca matplotlib para visualización de datos\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import seaborn as sns  # Importa la biblioteca seaborn para visualización de datos avanzada\n",
    "\n",
    "import warnings  # Importa la biblioteca warnings para manejar advertencias\n",
    "from sys import path  # Importa la biblioteca sys para manejar rutas del sistema\n",
    "import os  # Importa la biblioteca os para interactuar con el sistema operativo\n",
    "\n",
    "# Itera sobre los archivos en el directorio \"../resources/\" e imprime sus rutas\n",
    "for dirname, _, filenames in os.walk(\"../resources/\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "path.append(os.path.realpath(\"../\"))  # Agrega la ruta \"../\" al path del sistema\n",
    "\n",
    "from custom import functions  # Importa un módulo personalizado llamado \"functions\"\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\"\n",
    ")  # Ignora las advertencias durante la ejecución del programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Carga DataFrame_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../resources/v2_hitosExitoFalloColESol1.csv\", delimiter=\";\", skipinitialspace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Normalizacion de variables_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna \"sol1\" a números de punto flotante\n",
    "df[\"sol1\"] = df[\"sol1\"].astype(float)\n",
    "df[\"exitosos\"] = df[\"exitosos\"].astype(int)\n",
    "df[\"fallidos\"] = df[\"fallidos\"].astype(int)\n",
    "df[\"hito1\"] = df[\"hito1\"].astype(int)\n",
    "df[\"hito2\"] = df[\"hito2\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hito1</th>\n",
       "      <th>hito2</th>\n",
       "      <th>exitosos</th>\n",
       "      <th>fallidos</th>\n",
       "      <th>e0</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>...</th>\n",
       "      <th>e44</th>\n",
       "      <th>e45</th>\n",
       "      <th>e46</th>\n",
       "      <th>e47</th>\n",
       "      <th>e48</th>\n",
       "      <th>e49</th>\n",
       "      <th>e50</th>\n",
       "      <th>e51</th>\n",
       "      <th>e52</th>\n",
       "      <th>sol1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>...</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>839.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.353993</td>\n",
       "      <td>0.168057</td>\n",
       "      <td>7.476758</td>\n",
       "      <td>11.287247</td>\n",
       "      <td>0.505364</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352801</td>\n",
       "      <td>0.734207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.642789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.370917</td>\n",
       "      <td>1.929950</td>\n",
       "      <td>5.361101</td>\n",
       "      <td>8.432787</td>\n",
       "      <td>0.500269</td>\n",
       "      <td>0.097239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478126</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.832625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hito1       hito2    exitosos    fallidos          e0          e1  \\\n",
       "count  839.000000  839.000000  839.000000  839.000000  839.000000  839.000000   \n",
       "mean    13.353993    0.168057    7.476758   11.287247    0.505364    0.009535   \n",
       "std     10.370917    1.929950    5.361101    8.432787    0.500269    0.097239   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      3.000000    0.000000    3.000000    5.000000    0.000000    0.000000   \n",
       "50%     13.000000    0.000000    7.000000   10.000000    1.000000    0.000000   \n",
       "75%     20.000000    0.000000   11.000000   16.000000    1.000000    0.000000   \n",
       "max     42.000000   32.000000   28.000000   47.000000    1.000000    1.000000   \n",
       "\n",
       "          e2          e3          e4     e5  ...         e44    e45    e46  \\\n",
       "count  839.0  839.000000  839.000000  839.0  ...  839.000000  839.0  839.0   \n",
       "mean     0.0    0.352801    0.734207    0.0  ...    0.010727    0.0    0.0   \n",
       "std      0.0    0.478126    0.442018    0.0  ...    0.103076    0.0    0.0   \n",
       "min      0.0    0.000000    0.000000    0.0  ...    0.000000    0.0    0.0   \n",
       "25%      0.0    0.000000    0.000000    0.0  ...    0.000000    0.0    0.0   \n",
       "50%      0.0    0.000000    1.000000    0.0  ...    0.000000    0.0    0.0   \n",
       "75%      0.0    1.000000    1.000000    0.0  ...    0.000000    0.0    0.0   \n",
       "max      0.0    1.000000    1.000000    0.0  ...    1.000000    0.0    0.0   \n",
       "\n",
       "         e47    e48    e49    e50    e51    e52        sol1  \n",
       "count  839.0  839.0  839.0  839.0  839.0  839.0  839.000000  \n",
       "mean     0.0    0.0    0.0    0.0    0.0    0.0    3.642789  \n",
       "std      0.0    0.0    0.0    0.0    0.0    0.0    1.832625  \n",
       "min      0.0    0.0    0.0    0.0    0.0    0.0    1.000000  \n",
       "25%      0.0    0.0    0.0    0.0    0.0    0.0    2.200000  \n",
       "50%      0.0    0.0    0.0    0.0    0.0    0.0    3.700000  \n",
       "75%      0.0    0.0    0.0    0.0    0.0    0.0    5.100000  \n",
       "max      0.0    0.0    0.0    0.0    0.0    0.0    7.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Transformacion y generacion de Columnas_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hito1', 'hito2', 'exitosos', 'fallidos', 'e0', 'e1', 'e2', 'e3', 'e4',\n",
      "       'e5', 'e6', 'e7', 'e8', 'e9', 'e10', 'e11', 'e12', 'e13', 'e14', 'e15',\n",
      "       'e16', 'e17', 'e18', 'e19', 'e20', 'e21', 'e22', 'e23', 'e24', 'e25',\n",
      "       'e26', 'e27', 'e28', 'e29', 'e30', 'e31', 'e32', 'e33', 'e34', 'e35',\n",
      "       'e36', 'e37', 'e38', 'e39', 'e40', 'e41', 'e42', 'e43', 'e44', 'e45',\n",
      "       'e46', 'e47', 'e48', 'e49', 'e50', 'e51', 'e52', 'sol1', 'aprobado'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# creando columna aprobado y con la funcion set_in_aprobado_nota poblamos la nueva columna.\n",
    "df[\"aprobado\"] = df.apply(lambda x: functions.set_in_aprobado_nota(x[\"sol1\"]), axis=1)\n",
    "\n",
    "# revisamos la existencia de la nueva columna.\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Selección de características y variable objetivo para los modelos de clasificacion_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características y variable objetivo para los modelos de clasificacion.\n",
    "y = df[\"aprobado\"]\n",
    "X = df[\n",
    "    ['hito1', 'hito2', 'exitosos', 'fallidos', 'e0', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8', 'e9', 'e10', 'e11', 'e12', 'e13', 'e14', 'e15', 'e16', 'e17', 'e18', 'e19', 'e20', 'e21', 'e22', 'e23', 'e24', 'e25', 'e26', 'e27', 'e28', 'e29', 'e30', 'e31', 'e32', 'e33', 'e34', 'e35', 'e36', 'e37', 'e38', 'e39', 'e40', 'e41', 'e42', 'e43', 'e44', 'e45', 'e46', 'e47', 'e48', 'e49', 'e50', 'e51', 'e52']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos de clasificacion**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba usando train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1502)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Descripcion de configuraciones utilizadas_\n",
    "\n",
    "`DecisionTreeClassifier`\n",
    "\n",
    "- `min_samples_split:` (cantidad mínima de muestras para dividir): Se establece en 10, lo que indica que se requiere un mínimo de 10 muestras en un nodo para que se realice una división.\n",
    "- `min_samples_leaf:` (cantidad mínima de muestras en una hoja): Se establece en 5, lo que significa que se requiere un mínimo de 5 muestras en una hoja para que se considere como una hoja válida.\n",
    "\n",
    "`LogisticRegression`\n",
    "\n",
    "- `penalty:` (penalización) Se establece en \"l2\", lo que significa que se utiliza la regularización L2 (ridge) para evitar el sobreajuste.\n",
    "- `c:` (inverso de la fuerza de regularización) Se establece en 1.0, lo que indica una regularización moderada.\n",
    "- `solver:` (solucionador) Se establece en \"lbfgs\", que es un algoritmo de optimización utilizado para ajustar el modelo.\n",
    "- `max_iter:` (máximo número de iteraciones) Se establece en 150, lo que indica el número máximo de iteraciones permitidas para la convergencia del modelo.\n",
    "\n",
    "`RandomForestClassifier`\n",
    "\n",
    "- `max_depth` (máxima profundidad del árbol): Se establece en 10, lo que limita la profundidad máxima de los árboles en el bosque.\n",
    "- `min_samples_split` (cantidad mínima de muestras para dividir): Se establece en 10, lo que indica que se requiere un mínimo de 10 muestras en un nodo para que se realice una división.\n",
    "- `min_samples_leaf` (cantidad mínima de muestras en una hoja): Se establece en 5, lo que significa que se requiere un mínimo de 5 muestras en una hoja para que se considere como una hoja válida.\n",
    "- `random_state` (semilla para la generación de números aleatorios): Se establece en 1502, lo que garantiza la reproducibilidad de los resultados.\n",
    "- `n_estimators` (número de estimadores): Se establece en 500, lo que indica el número de árboles en el bosque.\n",
    "\n",
    "`XGBClassifier`\n",
    "\n",
    "- `learning_rate` (tasa de aprendizaje): Se establece en 0.1, lo que controla la velocidad de aprendizaje del algoritmo.\n",
    "- `max_depth` (máxima profundidad del árbol): Se establece en 10, lo que limita la profundidad máxima de los árboles.\n",
    "- `n_estimators` (número de estimadores): Se establece en 150, lo que determina el número de árboles en el modelo.\n",
    "- `subsample`: Se establece en 1.0, lo que indica que se utilizan todas las muestras en cada árbol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos de Clasificacion\n",
    "models_clasificacion = [\n",
    "    DecisionTreeClassifier(\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "    ),\n",
    "    LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=150),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=1502,\n",
    "        n_estimators=500,\n",
    "    ),\n",
    "    XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=150, subsample=1.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Aplicando StratifiedKfold y Entrenamiento_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Crear un diccionario para almacenar los resultados de las métricas para cada modelo\n",
    "results_train = {}\n",
    "\n",
    "# Calcular las métricas utilizando cross_validate\n",
    "for model in models_clasificacion:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, scoring=scoring)\n",
    "    results_train[model_name] = {\n",
    "        metric: scores['test_' + metric] for metric in scoring\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Realizar predicciones utilizando el mejor modelo sobre test_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Grafico Comparación de Métricas de Rendimiento (Conjunto de Entrenamiento) Modelos de Clasificación_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m width \u001b[39m=\u001b[39m \u001b[39m0.15\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i, metric \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(metrics):\n\u001b[1;32m----> 7\u001b[0m     scores \u001b[39m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m         np\u001b[39m.\u001b[39;49mmean(results_train[model_name][metric]) \u001b[39mfor\u001b[39;49;00m model_name \u001b[39min\u001b[39;49;00m models_clasificacion\n\u001b[0;32m      9\u001b[0m     ]\n\u001b[0;32m     10\u001b[0m     bars \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mbar(x \u001b[39m+\u001b[39m i \u001b[39m*\u001b[39m width, scores, width, label\u001b[39m=\u001b[39mmetric)\n\u001b[0;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m bar \u001b[39min\u001b[39;00m bars:\n",
      "Cell \u001b[1;32mIn[58], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m width \u001b[39m=\u001b[39m \u001b[39m0.15\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i, metric \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(metrics):\n\u001b[0;32m      7\u001b[0m     scores \u001b[39m=\u001b[39m [\n\u001b[1;32m----> 8\u001b[0m         np\u001b[39m.\u001b[39mmean(results_train[model_name][metric]) \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m models_clasificacion\n\u001b[0;32m      9\u001b[0m     ]\n\u001b[0;32m     10\u001b[0m     bars \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mbar(x \u001b[39m+\u001b[39m i \u001b[39m*\u001b[39m width, scores, width, label\u001b[39m=\u001b[39mmetric)\n\u001b[0;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m bar \u001b[39min\u001b[39;00m bars:\n",
      "\u001b[1;31mKeyError\u001b[0m: DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=10)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el gráfico de barras\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "x = np.arange(len(models_clasificacion))\n",
    "width = 0.15\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    scores = [\n",
    "        np.mean(results_train[model_name][metric]) for model_name in models_clasificacion\n",
    "    ]\n",
    "    bars = ax.bar(x + i * width, scores, width, label=metric)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height,\n",
    "            f\"{height:.2%}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "ax.set_xticks(x + len(metrics) * width / 2)\n",
    "ax.set_xticklabels([model.__class__.__name__ for model in models_clasificacion])\n",
    "plt.xlabel(\"Modelos de Clasificación\")\n",
    "plt.ylabel(\"Puntuación\")\n",
    "plt.title(\"Comparación de Métricas de Rendimiento (Conjunto de Entrenamiento)\")\n",
    "plt.legend(loc=\"center\", bbox_to_anchor=(0.5, -0.15), ncol=len(metrics))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Comparación de Métricas entre Modelos_\n",
    "\n",
    "`Accuracy (Precisión)`:\n",
    "El accuracy, o precisión, es una métrica que mide la proporción de instancias clasificadas correctamente sobre el total de instancias en los datos de prueba. En otras palabras, es la capacidad del modelo para predecir correctamente tanto las instancias positivas como las negativas. Un valor de accuracy alto indica un buen rendimiento general del modelo en la clasificación.\n",
    "\n",
    "- `Fórmula:\n",
    "Accuracy = (Verdaderos Positivos + Verdaderos Negativos) / Total de instancias`\n",
    "\n",
    "`Precision (Precisión)`:\n",
    "La precision es una métrica que mide la proporción de instancias clasificadas como positivas que son realmente positivas. Es la capacidad del modelo para evitar hacer falsas afirmaciones de que una instancia pertenece a la clase positiva cuando no lo hace. Una precision alta indica que el modelo tiene una baja tasa de falsos positivos.\n",
    "\n",
    "- `Fórmula:\n",
    "Precision = Verdaderos Positivos / (Verdaderos Positivos + Falsos Positivos)`\n",
    "\n",
    "`Recall (Recall o Sensibilidad)`:\n",
    "El recall, también conocido como sensibilidad o tasa de verdaderos positivos, mide la proporción de instancias positivas que son correctamente identificadas por el modelo. Es la capacidad del modelo para detectar y clasificar correctamente las instancias positivas. Un recall alto indica que el modelo tiene una baja tasa de falsos negativos.\n",
    "\n",
    "- `Fórmula:\n",
    "Recall = Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)`\n",
    "\n",
    "`F1 Score`:\n",
    "El F1 score es una métrica que combina la precision y el recall en una sola medida. Es la media armónica de la precision y el recall, y proporciona una evaluación equilibrada del rendimiento del modelo. El F1 score es especialmente útil cuando hay un desequilibrio entre las clases o cuando se desea tener un equilibrio entre la precision y el recall.\n",
    "\n",
    "- `Fórmula:\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)`\n",
    "\n",
    "`Stratified K-Fold Cross-Validation (Validación cruzada estratificada de K particiones)`:\n",
    "La validación cruzada estratificada de K particiones, o Stratified K-Fold CV, es una variante de K-Fold CV que tiene en cuenta la distribución de las clases en los datos al realizar la partición. En lugar de realizar la partición de forma aleatoria, Stratified K-Fold CV garantiza que la proporción de clases en cada partición sea lo más similar posible a la proporción de clases en el conjunto de datos original. Esto es especialmente útil cuando hay un desequilibrio entre las clases en los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Grafico de resultados mejor modelo Mean y R2_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análisis de los resultados del gráfico de Clasificación**\n",
    "\n",
    "En este trabajo de investigación, se realizó un análisis de clasificación comparando diferentes modelos. Los resultados obtenidos revelan que el modelo de clasificación RandomForestClassifier logró un mejor desempeño en términos de equilibrio F1 con un 62.53%, recall con un 58.90%, precisión con un 67.61% y exactitud con un 68.26% en comparación con los otros modelos evaluados.\n",
    "\n",
    "**Conclusión:** Con base en los resultados obtenidos, se puede concluir que el modelo RandomForestClassifier es el más adecuado para problemas de clasificación.\n",
    "\n",
    "- El mejor modelo en la validación fue: RandomForestClassifier 63.85%\n",
    "- Resultados del mejor modelo en el conjunto de prueba:\n",
    "  - Mean Squared Error: 36.3%\n",
    "  - R2 Score: -45.3%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos de Regresion**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinearRegression`:\n",
    "\n",
    "Es un modelo de regresión lineal que busca establecer una relación lineal entre las características y la variable objetivo continua.\n",
    "Se basa en ajustar una línea recta a los datos que minimiza la suma de los errores cuadráticos.\n",
    "Estima los coeficientes de las características para predecir los valores de la variable objetivo.\n",
    "\n",
    "- `positive` (positividad): Se establece en True, lo que indica que los coeficientes del modelo de regresión lineal se forzarán a ser positivos.\n",
    "- `fit_intercept` (ajuste de intersección): Se establece en True, lo que significa que se calculará la intersección (ordenada al origen) en el modelo de regresión lineal.\n",
    "\n",
    "`DecisionTreeRegressor`:\n",
    "\n",
    "Es un modelo de regresión basado en árboles de decisión.\n",
    "Divide recursivamente el espacio de características en subespacios más pequeños para predecir los valores de las muestras.\n",
    "Cada nodo interno representa una pregunta o prueba sobre una característica, y las hojas representan los valores de regresión.\n",
    "\n",
    "- `min_samples_split` (cantidad mínima de muestras para dividir): Se establece en 5, lo que indica que se requiere un mínimo de 5 muestras en un nodo para que se realice una división.\n",
    "- `min_samples_leaf` (cantidad mínima de muestras en una hoja): Se establece en 3, lo que significa que se requiere un mínimo de 3 muestras en una hoja para que se considere como una hoja válida.\n",
    "\n",
    "`KNeighborsRegressor`:\n",
    "\n",
    "Es un modelo de regresión basado en vecinos más cercanos (K-Nearest Neighbors).\n",
    "Estima el valor de la variable objetivo mediante la media (promedio) de los valores de los K vecinos más cercanos en el espacio de características.\n",
    "Puede manejar problemas de regresión con múltiples características y valores continuos.\n",
    "\n",
    "- `n_neighbors` (número de vecinos): Se establece en 8, lo que indica que se utilizarán los 8 vecinos más cercanos para predecir el valor de la variable objetivo en el modelo de regresión basado en vecinos más cercanos.\n",
    "\n",
    "`NOTA: Para estos modelos se utiliza la columna sol1 donde nota igual o superior a 4 es aprobado`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Selección de características y variable objetivo para los modelos de Regresion_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Definir los modelos de regresión_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Realizar K-Fold Cross-Validation y entrenamiento en los datos de entrenados y obtener las métricas para cada modelo_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Grafico Comparación de Medidas de Rendimiento Modelos de Regresión_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Medidas de rendimiento de cada modelo_\n",
    "\n",
    "`MSE (Mean Squared Error) - Error Cuadrático Medio`: Es la media de los errores al cuadrado entre las predicciones y los valores reales. El MSE proporciona una medida de la calidad general del modelo, donde valores más bajos indican que las predicciones se ajustan mejor a los datos reales.\n",
    "\n",
    "`MAE (Mean Absolute Error) - Error Absoluto Medio`: Es la media de los errores absolutos entre las predicciones y los valores reales. El MAE representa la magnitud promedio de los errores de predicción y se utiliza para evaluar la precisión del modelo. Valores más bajos indican una mejor precisión.\n",
    "\n",
    "`R2 (Coeficiente de determinación)`: Es una medida de qué tan bien se ajustan las predicciones del modelo a los datos reales. R2 varía entre 0 y 1, donde 1 indica un ajuste perfecto del modelo a los datos. Un valor más cercano a 1 indica un mejor ajuste del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Identificar el mejor modelo_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análisis de los resultados del gráfico de regresión**\n",
    "\n",
    "En este trabajo de investigación, se realizaron análisis de regresión para evaluar diferentes modelos. Los resultados obtenidos revelan que el modelo de LinearRegression obtuvo los mejores resultados en todas sus características. Se logró un MSE de 3.6% y un MAE de 1.6%, valores inferiores a los de los otros modelos evaluados. Además, el modelo de LinearRegression presentó un R2 más cercano a 1, con un aumento del 0.1% en comparación con los demás modelos.\n",
    "\n",
    "**Conclusión:** De acuerdo con los hallazgos de este estudio, se puede concluir que el modelo de LinearRegression es el más adecuado para este análisis de regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusión Final de la Investigación**\n",
    "\n",
    "En este estudio de investigación, se realizó una comparación exhaustiva de diferentes algoritmos de modelos predictivos para determinar cuál es el más adecuado en términos de origen de datos. El objetivo principal fue evaluar y seleccionar el mejor modelo para abordar el problema de manera efectiva.\n",
    "\n",
    "Después de analizar y comparar varios algoritmos, se llegó a la conclusión de que el modelo de clasificación RandomForestClassifier se destaca como el enfoque más efectivo para el origen de datos en cuestión. Este modelo demostró un mejor desempeño en términos de equilibrio F1 con un 62.08%, recall con un 58.67%, precisión con un 66.54% y exactitud con un 68.11% en comparación con los otros modelos evaluados. Estos resultados indican que el modelo RandomForestClassifier es altamente eficaz para problemas de clasificación.\n",
    "\n",
    "Es importante destacar que este experimento forma parte de una investigación más amplia para una tesis en curso. Al realizar la comparación de algoritmos de modelos predictivos, se pudo determinar que la clasificación es la mejor manera de tratar el origen de los datos en este contexto específico.\n",
    "\n",
    "Se recomienda el uso del modelo RandomForestClassifier para futuros análisis y aplicaciones similares. Sin embargo, es importante tener en cuenta que la selección del algoritmo de modelo predictivo adecuado debe considerar las características específicas de los datos y el objetivo de la investigación.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
